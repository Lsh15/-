{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Twitter\n",
    "from time import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading https://files.pythonhosted.org/packages/52/04/c362f34f666f0ddc7cf593805e64d64fa670ed96fd9302e68549dd48287d/mlxtend-0.17.0-py2.py3-none-any.whl (1.3MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from mlxtend) (41.0.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from mlxtend) (3.0.3)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.1)\n",
      "Collecting joblib>=0.13.2 (from mlxtend)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from mlxtend) (0.24.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from mlxtend) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from mlxtend) (1.16.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2018.9)\n",
      "Requirement already satisfied: six in c:\\users\\ce206-26\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.12.0)\n",
      "Installing collected packages: joblib, mlxtend\n",
      "Successfully installed joblib-0.13.2 mlxtend-0.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/CE206-26/Desktop/크롤링구글맵스라벨링1.csv\",encoding='CP949')\n",
    "df2 = pd.read_csv(\"C:/Users/CE206-26/Desktop/리뷰.csv\",encoding='CP949')\n",
    "df_train = df1[330:]\n",
    "df_test = df1[331:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1['라벨링'] = df1['라벨링'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['라벨링'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      5\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "5      1\n",
       "6      1\n",
       "7      1\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     2\n",
       "13     4\n",
       "14     3\n",
       "15     3\n",
       "16     6\n",
       "17     1\n",
       "18     2\n",
       "19     2\n",
       "20     3\n",
       "21     2\n",
       "22     3\n",
       "23     1\n",
       "24     1\n",
       "25     1\n",
       "26     1\n",
       "27     2\n",
       "28     2\n",
       "29     2\n",
       "      ..\n",
       "457    3\n",
       "458    1\n",
       "459    2\n",
       "460    1\n",
       "461    5\n",
       "462    2\n",
       "463    6\n",
       "464    4\n",
       "465    1\n",
       "466    3\n",
       "467    3\n",
       "468    3\n",
       "469    3\n",
       "470    3\n",
       "471    3\n",
       "472    1\n",
       "473    1\n",
       "474    6\n",
       "475    1\n",
       "476    6\n",
       "477    6\n",
       "478    6\n",
       "479    6\n",
       "480    1\n",
       "481    1\n",
       "482    1\n",
       "483    1\n",
       "484    6\n",
       "485    6\n",
       "486    2\n",
       "Name: 라벨링, Length: 487, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['라벨링']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df1[330:]\n",
    "df_test = df1[331:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "twitter = Twitter()\n",
    "def tokenizer_twitter_morphs(doc):\n",
    "    return twitter.morphs(doc)\n",
    "\n",
    "def tokenizer_twitter_noun(doc):\n",
    "    return twitter.nouns(doc)\n",
    "\n",
    "def tokenizer_twitter_pos(doc):\n",
    "    return twitter.pos(doc, norm=True, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = Komoran()\n",
    "def tokenizer_noun(doc):\n",
    "    return komoran.nouns(doc)\n",
    "\n",
    "def tokenizer_morphs(doc):\n",
    "    return komoran.morphs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_train['token_review'] = df_train['리뷰'].apply(tokenizer_twitter_morphs)\n",
    "df_test['X_test_tokkened'] = df_test['리뷰'].apply(tokenizer_twitter_morphs)\n",
    "tokens = [ t for d in df_train['token_review'] for t in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = nltk.Text(tokens, name='NMSC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_train_docs = [TaggedDocument(d, c) for d, c in df_train[['token_review', '라벨링']].values]\n",
    "tagged_test_docs = [TaggedDocument(d, c) for d, c in df_test[['X_test_tokkened', '라벨링']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 11:54:56,307 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectorizer = Doc2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 11:54:56,418 : INFO : collecting all words and their counts\n",
      "2019-08-21 11:54:56,419 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-08-21 11:54:56,481 : INFO : collected 16418 word types and 6 unique tags from a corpus of 157 examples and 136053 words\n",
      "2019-08-21 11:54:56,482 : INFO : Loading a fresh vocabulary\n",
      "2019-08-21 11:54:56,506 : INFO : effective_min_count=5 retains 3168 unique words (19% of original 16418, drops 13250)\n",
      "2019-08-21 11:54:56,508 : INFO : effective_min_count=5 leaves 115978 word corpus (85% of original 136053, drops 20075)\n",
      "2019-08-21 11:54:56,529 : INFO : deleting the raw counts dictionary of 16418 items\n",
      "2019-08-21 11:54:56,531 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2019-08-21 11:54:56,533 : INFO : downsampling leaves estimated 89686 word corpus (77.3% of prior 115978)\n",
      "2019-08-21 11:54:56,543 : INFO : estimated required memory for 3168 words and 100 dimensions: 4122000 bytes\n",
      "2019-08-21 11:54:56,544 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/m,d100,n5,w5,mc5,s0.001,t3)\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "2019-08-21 11:54:56,773 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:54:56,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:56,908 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:56,910 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:56,911 : INFO : EPOCH - 1 : training on 136053 raw words (89729 effective words) took 0.1s, 666455 effective words/s\n",
      "2019-08-21 11:54:57,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:57,049 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:57,051 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:57,053 : INFO : EPOCH - 2 : training on 136053 raw words (89819 effective words) took 0.1s, 650092 effective words/s\n",
      "2019-08-21 11:54:57,180 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:57,188 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:57,190 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:57,191 : INFO : EPOCH - 3 : training on 136053 raw words (89928 effective words) took 0.1s, 665939 effective words/s\n",
      "2019-08-21 11:54:57,330 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:57,333 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:57,334 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:57,336 : INFO : EPOCH - 4 : training on 136053 raw words (89990 effective words) took 0.1s, 648716 effective words/s\n",
      "2019-08-21 11:54:57,451 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:57,453 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:57,456 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:57,457 : INFO : EPOCH - 5 : training on 136053 raw words (89762 effective words) took 0.1s, 761519 effective words/s\n",
      "2019-08-21 11:54:57,459 : INFO : training on a 680265 raw words (449228 effective words) took 0.7s, 656155 effective words/s\n",
      "2019-08-21 11:54:57,460 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-08-21 11:54:57,462 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:54:57,593 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:57,595 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:57,601 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:57,602 : INFO : EPOCH - 1 : training on 136053 raw words (89898 effective words) took 0.1s, 663122 effective words/s\n",
      "2019-08-21 11:54:57,723 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:57,725 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:57,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:57,733 : INFO : EPOCH - 2 : training on 136053 raw words (89799 effective words) took 0.1s, 704403 effective words/s\n",
      "2019-08-21 11:54:57,854 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:57,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:57,860 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:57,861 : INFO : EPOCH - 3 : training on 136053 raw words (89920 effective words) took 0.1s, 728508 effective words/s\n",
      "2019-08-21 11:54:57,991 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:57,995 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:57,999 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:58,000 : INFO : EPOCH - 4 : training on 136053 raw words (89843 effective words) took 0.1s, 671547 effective words/s\n",
      "2019-08-21 11:54:58,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:58,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:58,133 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:58,134 : INFO : EPOCH - 5 : training on 136053 raw words (89777 effective words) took 0.1s, 687584 effective words/s\n",
      "2019-08-21 11:54:58,135 : INFO : training on a 680265 raw words (449237 effective words) took 0.7s, 668900 effective words/s\n",
      "2019-08-21 11:54:58,136 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:54:58,282 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:58,284 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:58,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:58,290 : INFO : EPOCH - 1 : training on 136053 raw words (89784 effective words) took 0.1s, 691404 effective words/s\n",
      "2019-08-21 11:54:58,415 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:58,419 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:58,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:58,423 : INFO : EPOCH - 2 : training on 136053 raw words (89815 effective words) took 0.1s, 704993 effective words/s\n",
      "2019-08-21 11:54:58,557 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:58,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:58,564 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:58,566 : INFO : EPOCH - 3 : training on 136053 raw words (89968 effective words) took 0.1s, 643319 effective words/s\n",
      "2019-08-21 11:54:58,677 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:58,680 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:58,684 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:58,685 : INFO : EPOCH - 4 : training on 136053 raw words (89894 effective words) took 0.1s, 773069 effective words/s\n",
      "2019-08-21 11:54:58,804 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:58,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:58,811 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:58,812 : INFO : EPOCH - 5 : training on 136053 raw words (89924 effective words) took 0.1s, 727297 effective words/s\n",
      "2019-08-21 11:54:58,813 : INFO : training on a 680265 raw words (449385 effective words) took 0.7s, 663747 effective words/s\n",
      "2019-08-21 11:54:58,814 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:54:58,931 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:58,933 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:58,934 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:58,935 : INFO : EPOCH - 1 : training on 136053 raw words (89730 effective words) took 0.1s, 761982 effective words/s\n",
      "2019-08-21 11:54:59,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:59,060 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:59,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:59,063 : INFO : EPOCH - 2 : training on 136053 raw words (89821 effective words) took 0.1s, 731472 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 11:54:59,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:59,181 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:59,186 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:59,188 : INFO : EPOCH - 3 : training on 136053 raw words (89867 effective words) took 0.1s, 746339 effective words/s\n",
      "2019-08-21 11:54:59,306 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:59,311 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:59,314 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:59,315 : INFO : EPOCH - 4 : training on 136053 raw words (89682 effective words) took 0.1s, 720183 effective words/s\n",
      "2019-08-21 11:54:59,432 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:59,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:59,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:59,441 : INFO : EPOCH - 5 : training on 136053 raw words (89714 effective words) took 0.1s, 750118 effective words/s\n",
      "2019-08-21 11:54:59,442 : INFO : training on a 680265 raw words (448814 effective words) took 0.6s, 715358 effective words/s\n",
      "2019-08-21 11:54:59,443 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:54:59,556 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:59,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:59,565 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:59,566 : INFO : EPOCH - 1 : training on 136053 raw words (89756 effective words) took 0.1s, 750395 effective words/s\n",
      "2019-08-21 11:54:59,677 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:59,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:59,679 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:59,681 : INFO : EPOCH - 2 : training on 136053 raw words (89892 effective words) took 0.1s, 803958 effective words/s\n",
      "2019-08-21 11:54:59,808 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:59,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:59,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:59,819 : INFO : EPOCH - 3 : training on 136053 raw words (89928 effective words) took 0.1s, 687090 effective words/s\n",
      "2019-08-21 11:54:59,939 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:54:59,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:54:59,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:54:59,944 : INFO : EPOCH - 4 : training on 136053 raw words (89807 effective words) took 0.1s, 747212 effective words/s\n",
      "2019-08-21 11:55:00,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:00,066 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:00,070 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:00,072 : INFO : EPOCH - 5 : training on 136053 raw words (89794 effective words) took 0.1s, 723686 effective words/s\n",
      "2019-08-21 11:55:00,073 : INFO : training on a 680265 raw words (449177 effective words) took 0.6s, 714563 effective words/s\n",
      "2019-08-21 11:55:00,074 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:55:00,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:00,196 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:00,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:00,202 : INFO : EPOCH - 1 : training on 136053 raw words (89765 effective words) took 0.1s, 718192 effective words/s\n",
      "2019-08-21 11:55:00,319 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:00,322 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:00,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:00,328 : INFO : EPOCH - 2 : training on 136053 raw words (89964 effective words) took 0.1s, 728444 effective words/s\n",
      "2019-08-21 11:55:00,441 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:00,443 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:00,449 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:00,450 : INFO : EPOCH - 3 : training on 136053 raw words (89967 effective words) took 0.1s, 756265 effective words/s\n",
      "2019-08-21 11:55:00,583 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:00,591 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:00,593 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:00,594 : INFO : EPOCH - 4 : training on 136053 raw words (89718 effective words) took 0.1s, 635834 effective words/s\n",
      "2019-08-21 11:55:00,711 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:00,716 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:00,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:00,721 : INFO : EPOCH - 5 : training on 136053 raw words (89901 effective words) took 0.1s, 744103 effective words/s\n",
      "2019-08-21 11:55:00,721 : INFO : training on a 680265 raw words (449315 effective words) took 0.6s, 693837 effective words/s\n",
      "2019-08-21 11:55:00,722 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:55:00,829 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:00,834 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:00,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:00,838 : INFO : EPOCH - 1 : training on 136053 raw words (89858 effective words) took 0.1s, 799825 effective words/s\n",
      "2019-08-21 11:55:00,953 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:00,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:00,960 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:00,961 : INFO : EPOCH - 2 : training on 136053 raw words (90146 effective words) took 0.1s, 749908 effective words/s\n",
      "2019-08-21 11:55:01,078 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:01,084 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:01,086 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:01,087 : INFO : EPOCH - 3 : training on 136053 raw words (89849 effective words) took 0.1s, 735599 effective words/s\n",
      "2019-08-21 11:55:01,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:01,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:01,196 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:01,198 : INFO : EPOCH - 4 : training on 136053 raw words (89894 effective words) took 0.1s, 836506 effective words/s\n",
      "2019-08-21 11:55:01,321 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:01,324 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:01,329 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:01,331 : INFO : EPOCH - 5 : training on 136053 raw words (89773 effective words) took 0.1s, 690608 effective words/s\n",
      "2019-08-21 11:55:01,332 : INFO : training on a 680265 raw words (449520 effective words) took 0.6s, 738235 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 11:55:01,333 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:55:01,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:01,445 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:01,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:01,448 : INFO : EPOCH - 1 : training on 136053 raw words (89824 effective words) took 0.1s, 810050 effective words/s\n",
      "2019-08-21 11:55:01,559 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:01,561 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:01,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:01,569 : INFO : EPOCH - 2 : training on 136053 raw words (89750 effective words) took 0.1s, 758308 effective words/s\n",
      "2019-08-21 11:55:01,685 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:01,688 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:01,692 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:01,693 : INFO : EPOCH - 3 : training on 136053 raw words (89972 effective words) took 0.1s, 749515 effective words/s\n",
      "2019-08-21 11:55:01,802 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:01,804 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:01,807 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:01,808 : INFO : EPOCH - 4 : training on 136053 raw words (89973 effective words) took 0.1s, 807766 effective words/s\n",
      "2019-08-21 11:55:01,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:01,924 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:01,928 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:01,930 : INFO : EPOCH - 5 : training on 136053 raw words (89709 effective words) took 0.1s, 754016 effective words/s\n",
      "2019-08-21 11:55:01,931 : INFO : training on a 680265 raw words (449228 effective words) took 0.6s, 753450 effective words/s\n",
      "2019-08-21 11:55:01,932 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:55:02,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:02,052 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:02,057 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:02,058 : INFO : EPOCH - 1 : training on 136053 raw words (89808 effective words) took 0.1s, 741146 effective words/s\n",
      "2019-08-21 11:55:02,167 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:02,170 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:02,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:02,175 : INFO : EPOCH - 2 : training on 136053 raw words (89896 effective words) took 0.1s, 789579 effective words/s\n",
      "2019-08-21 11:55:02,291 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:02,293 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:02,298 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:02,299 : INFO : EPOCH - 3 : training on 136053 raw words (89895 effective words) took 0.1s, 745852 effective words/s\n",
      "2019-08-21 11:55:02,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:02,419 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:02,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:02,422 : INFO : EPOCH - 4 : training on 136053 raw words (89797 effective words) took 0.1s, 748842 effective words/s\n",
      "2019-08-21 11:55:02,530 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:02,538 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:02,542 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:02,544 : INFO : EPOCH - 5 : training on 136053 raw words (89883 effective words) took 0.1s, 760363 effective words/s\n",
      "2019-08-21 11:55:02,545 : INFO : training on a 680265 raw words (449279 effective words) took 0.6s, 733653 effective words/s\n",
      "2019-08-21 11:55:02,546 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-21 11:55:02,671 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:02,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:02,684 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:02,686 : INFO : EPOCH - 1 : training on 136053 raw words (89985 effective words) took 0.1s, 670415 effective words/s\n",
      "2019-08-21 11:55:02,809 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:02,812 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:02,818 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:02,819 : INFO : EPOCH - 2 : training on 136053 raw words (89958 effective words) took 0.1s, 688351 effective words/s\n",
      "2019-08-21 11:55:02,928 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:02,930 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:02,931 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:02,933 : INFO : EPOCH - 3 : training on 136053 raw words (89965 effective words) took 0.1s, 830196 effective words/s\n",
      "2019-08-21 11:55:03,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:03,053 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:03,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:03,057 : INFO : EPOCH - 4 : training on 136053 raw words (89919 effective words) took 0.1s, 747003 effective words/s\n",
      "2019-08-21 11:55:03,170 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-21 11:55:03,172 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-21 11:55:03,177 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-21 11:55:03,178 : INFO : EPOCH - 5 : training on 136053 raw words (89868 effective words) took 0.1s, 760813 effective words/s\n",
      "2019-08-21 11:55:03,179 : INFO : training on a 680265 raw words (449695 effective words) took 0.6s, 711771 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During Time: 6.407311201095581\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "end = time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 11:55:03,187 : INFO : saving Doc2Vec object under Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model, separately None\n",
      "2019-08-21 11:55:03,230 : INFO : saved Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model'\n",
    "doc_vectorizer.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 11:55:03,268 : INFO : loading Doc2Vec object from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model\n",
      "2019-08-21 11:55:03,305 : INFO : loading vocabulary recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.vocabulary.* with mmap=None\n",
      "2019-08-21 11:55:03,307 : INFO : loading trainables recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.trainables.* with mmap=None\n",
      "2019-08-21 11:55:03,308 : INFO : loading wv recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.wv.* with mmap=None\n",
      "2019-08-21 11:55:03,310 : INFO : loading docvecs recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.docvecs.* with mmap=None\n",
      "2019-08-21 11:55:03,312 : INFO : loaded Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer = Doc2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 11:55:03,362 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('쏘', 0.52012699842453), ('맛있다', 0.5154653191566467), ('아이스크림', 0.46574676036834717), ('값', 0.46423691511154175), ('그닥', 0.4578384757041931), ('비싸지만', 0.4543248116970062), ('선', 0.45016780495643616), ('그릇', 0.4412122368812561), ('괜찮음', 0.4396941065788269), ('케익', 0.4357563853263855)]\n"
     ]
    }
   ],
   "source": [
    "print(doc_vectorizer.wv.most_similar('맛'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "y_train = [doc.tags for doc in tagged_train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_test_docs]\n",
    "y_test = [doc.tags for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 157\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.asarray(y_train)\n",
    "y_test_np = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_np[0]), len(X_test_np[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32240194,  0.9797233 , -0.48346397, -0.32138652,  0.91758746,\n",
       "       -0.50063825,  0.7603144 ,  0.6418833 ,  0.8216492 ,  0.6387633 ,\n",
       "        1.2477922 ,  0.76412565, -0.5739062 ,  0.7597043 ,  0.34649777,\n",
       "       -0.5157313 ,  0.3484775 , -0.53635746, -0.5995913 ,  0.37935355,\n",
       "        0.46880415, -0.11298016, -0.40156373,  0.1328461 , -0.71088064,\n",
       "       -1.2638628 ,  0.35048416, -0.4227118 ,  0.6547124 ,  0.1337249 ,\n",
       "        0.83857256,  0.3434105 ,  0.40196168, -0.49190608,  0.10491703,\n",
       "        0.7737773 ,  0.34125313,  0.15244994,  0.77955395,  0.18279304,\n",
       "       -0.2579207 , -0.12586984,  0.4946975 , -0.11855018, -0.06814502,\n",
       "       -0.72022796,  1.0170424 ,  0.05628105,  0.42932215, -0.2125378 ,\n",
       "        0.37252593,  0.19510572, -0.05568693, -1.0334122 ,  0.7758002 ,\n",
       "       -0.43360257,  0.15822122, -0.17308912, -0.9756206 , -0.47529104,\n",
       "        0.98124266, -0.82184255,  0.58320296,  0.49044496,  0.14933486,\n",
       "        0.37143224,  0.01298718,  0.7329966 ,  0.07056604, -0.26527566,\n",
       "       -0.03178933,  1.011577  ,  0.25018597,  0.41123044, -0.53027284,\n",
       "       -0.10798905,  0.07889076,  0.09739953, -0.5316146 ,  0.444373  ,\n",
       "        0.4319705 ,  0.43120795,  0.64929247, -0.29751182, -0.03032894,\n",
       "        0.71367687,  0.6968882 , -0.2689271 ,  0.06282271, -0.36522087,\n",
       "       -0.5311417 , -0.77777183, -0.50897086, -0.6247226 , -0.71626616,\n",
       "       -0.267237  , -0.51641417, -0.60600156,  0.78021   ,  0.29127643],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53851, 7)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.eye(7)[y_train_np.astype('int').reshape(-1)]\n",
    "y_test_np = np.eye(7)[y_test_np.astype('int').reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = KNeighborsClassifier(n_neighbors = 6, p=2, metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.fit(X_train_np,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 테스트 개수:156, 오류개수:38\n",
      "정확도: 0.756\n"
     ]
    }
   ],
   "source": [
    "print('총 테스트 개수:%d, 오류개수:%d' %(len(y_test), (y_test != y_pred).sum()))\n",
    "print('정확도: %.3f' %accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Filler values must be provided when X has more than 2 training features.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-632af5d4d007>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_combind_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_combined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_decision_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_combind_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlxtend\\plotting\\decision_regions.py\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[1;34m(X, y, clf, feature_index, filler_feature_values, filler_feature_ranges, ax, X_highlight, res, zoom_factor, legend, hide_spines, markers, colors, scatter_kwargs, contourf_kwargs, scatter_highlight_kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfiller_feature_values\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             raise ValueError('Filler values must be provided when '\n\u001b[0m\u001b[0;32m    179\u001b[0m                              'X has more than 2 training features.')\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Filler values must be provided when X has more than 2 training features."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADYBJREFUeJzt3HGI33d9x/Hny8ROprWO5QRJou1YuhrKoO7oOoRZ0Y20fyT/FEmguEppwK0OZhE6HCr1rylDELJptolT0Fr9Qw+J5A9X6RAjudJZmpTALTpzROhZu/5TtGZ774/fT++4XHLf3v3uLt77+YDA7/v7fX6/e+fD3TO/fH/3+6WqkCRtf6/a6gEkSZvD4EtSEwZfkpow+JLUhMGXpCYMviQ1sWrwk3wuyXNJnrnC7Uny6SRzSZ5O8rbJjylJWq8hz/A/Dxy4yu13AfvGf44C/7T+sSRJk7Zq8KvqCeBnV1lyCPhCjZwC3pDkTZMaUJI0GTsn8Bi7gQtLjufH1/1k+cIkRxn9L4DXvva1f3TLLbdM4MtLUh9PPvnkT6tqai33nUTws8J1K35eQ1UdB44DTE9P1+zs7AS+vCT1keS/13rfSfyWzjywd8nxHuDiBB5XkjRBkwj+DPDe8W/r3AG8WFWXnc6RJG2tVU/pJPkycCewK8k88FHg1QBV9RngBHA3MAe8BLxvo4aVJK3dqsGvqiOr3F7AX01sIknShvCdtpLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDUxKPhJDiQ5l2QuycMr3P7mJI8neSrJ00nunvyokqT1WDX4SXYAx4C7gP3AkST7ly37O+CxqroNOAz846QHlSStz5Bn+LcDc1V1vqpeBh4FDi1bU8Drx5dvAC5ObkRJ0iQMCf5u4MKS4/nxdUt9DLg3yTxwAvjASg+U5GiS2SSzCwsLaxhXkrRWQ4KfFa6rZcdHgM9X1R7gbuCLSS577Ko6XlXTVTU9NTX1yqeVJK3ZkODPA3uXHO/h8lM29wOPAVTV94DXALsmMaAkaTKGBP80sC/JTUmuY/Si7MyyNT8G3gWQ5K2Mgu85G0m6hqwa/Kq6BDwInASeZfTbOGeSPJLk4HjZQ8ADSX4AfBm4r6qWn/aRJG2hnUMWVdUJRi/GLr3uI0sunwXePtnRJEmT5DttJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNDAp+kgNJziWZS/LwFda8J8nZJGeSfGmyY0qS1mvnaguS7ACOAX8GzAOnk8xU1dkla/YBfwu8vapeSPLGjRpYkrQ2Q57h3w7MVdX5qnoZeBQ4tGzNA8CxqnoBoKqem+yYkqT1GhL83cCFJcfz4+uWuhm4Ocl3k5xKcmClB0pyNMlsktmFhYW1TSxJWpMhwc8K19Wy453APuBO4AjwL0necNmdqo5X1XRVTU9NTb3SWSVJ6zAk+PPA3iXHe4CLK6z5RlX9sqp+CJxj9A+AJOkaMST4p4F9SW5Kch1wGJhZtubrwDsBkuxidIrn/CQHlSStz6rBr6pLwIPASeBZ4LGqOpPkkSQHx8tOAs8nOQs8Dnyoqp7fqKElSa9cqpafjt8c09PTNTs7uyVfW5J+UyV5sqqm13Jf32krSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSE4OCn+RAknNJ5pI8fJV19ySpJNOTG1GSNAmrBj/JDuAYcBewHziSZP8K664H/hr4/qSHlCSt35Bn+LcDc1V1vqpeBh4FDq2w7uPAJ4CfT3A+SdKEDAn+buDCkuP58XW/luQ2YG9VffNqD5TkaJLZJLMLCwuveFhJ0toNCX5WuK5+fWPyKuBTwEOrPVBVHa+q6aqanpqaGj6lJGndhgR/Hti75HgPcHHJ8fXArcB3kvwIuAOY8YVbSbq2DAn+aWBfkpuSXAccBmZ+dWNVvVhVu6rqxqq6ETgFHKyq2Q2ZWJK0JqsGv6ouAQ8CJ4Fngceq6kySR5Ic3OgBJUmTsXPIoqo6AZxYdt1HrrD2zvWPJUmaNN9pK0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqYlDwkxxIci7JXJKHV7j9g0nOJnk6ybeTvGXyo0qS1mPV4CfZARwD7gL2A0eS7F+27Clguqr+EPga8IlJDypJWp8hz/BvB+aq6nxVvQw8ChxauqCqHq+ql8aHp4A9kx1TkrReQ4K/G7iw5Hh+fN2V3A98a6UbkhxNMptkdmFhYfiUkqR1GxL8rHBdrbgwuReYBj650u1VdbyqpqtqempqaviUkqR12zlgzTywd8nxHuDi8kVJ3g18GHhHVf1iMuNJkiZlyDP808C+JDcluQ44DMwsXZDkNuCzwMGqem7yY0qS1mvV4FfVJeBB4CTwLPBYVZ1J8kiSg+NlnwReB3w1yX8mmbnCw0mStsiQUzpU1QngxLLrPrLk8rsnPJckacJ8p60kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNDAp+kgNJziWZS/LwCrf/VpKvjG//fpIbJz2oJGl9Vg1+kh3AMeAuYD9wJMn+ZcvuB16oqt8HPgX8/aQHlSStz5Bn+LcDc1V1vqpeBh4FDi1bcwj4t/HlrwHvSpLJjSlJWq+dA9bsBi4sOZ4H/vhKa6rqUpIXgd8Ffrp0UZKjwNHx4S+SPLOWobehXSzbq8bci0XuxSL3YtEfrPWOQ4K/0jP1WsMaquo4cBwgyWxVTQ/4+tuee7HIvVjkXixyLxYlmV3rfYec0pkH9i453gNcvNKaJDuBG4CfrXUoSdLkDQn+aWBfkpuSXAccBmaWrZkB/mJ8+R7g36vqsmf4kqSts+opnfE5+QeBk8AO4HNVdSbJI8BsVc0A/wp8Mckco2f2hwd87ePrmHu7cS8WuReL3ItF7sWiNe9FfCIuST34TltJasLgS1ITGx58P5Zh0YC9+GCSs0meTvLtJG/Zijk3w2p7sWTdPUkqybb9lbwhe5HkPePvjTNJvrTZM26WAT8jb07yeJKnxj8nd2/FnBstyeeSPHel9ypl5NPjfXo6ydsGPXBVbdgfRi/y/hfwe8B1wA+A/cvW/CXwmfHlw8BXNnKmrfozcC/eCfz2+PL7O+/FeN31wBPAKWB6q+fewu+LfcBTwO+Mj9+41XNv4V4cB94/vrwf+NFWz71Be/GnwNuAZ65w+93Atxi9B+oO4PtDHnejn+H7sQyLVt2Lqnq8ql4aH55i9J6H7WjI9wXAx4FPAD/fzOE22ZC9eAA4VlUvAFTVc5s842YZshcFvH58+QYuf0/QtlBVT3D19zIdAr5QI6eANyR502qPu9HBX+ljGXZfaU1VXQJ+9bEM282QvVjqfkb/gm9Hq+5FktuAvVX1zc0cbAsM+b64Gbg5yXeTnEpyYNOm21xD9uJjwL1J5oETwAc2Z7RrzivtCTDsoxXWY2Ify7ANDP57JrkXmAbesaETbZ2r7kWSVzH61NX7NmugLTTk+2Ino9M6dzL6X99/JLm1qv5ng2fbbEP24gjw+ar6hyR/wuj9P7dW1f9t/HjXlDV1c6Of4fuxDIuG7AVJ3g18GDhYVb/YpNk222p7cT1wK/CdJD9idI5yZpu+cDv0Z+QbVfXLqvohcI7RPwDbzZC9uB94DKCqvge8htEHq3UzqCfLbXTw/ViGRavuxfg0xmcZxX67nqeFVfaiql6sql1VdWNV3cjo9YyDVbXmD426hg35Gfk6oxf0SbKL0Sme85s65eYYshc/Bt4FkOStjIK/sKlTXhtmgPeOf1vnDuDFqvrJanfa0FM6tXEfy/AbZ+BefBJ4HfDV8evWP66qg1s29AYZuBctDNyLk8CfJzkL/C/woap6fuum3hgD9+Ih4J+T/A2jUxj3bccniEm+zOgU3q7x6xUfBV4NUFWfYfT6xd3AHPAS8L5Bj7sN90qStALfaStJTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ18f+GmWq6NWLIwgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_combind_std = np.vstack((X_train,X_test))\n",
    "y_combined = np.hstack((y_train,y_test))\n",
    "plot_decision_regions(X=X_combind_std, y=y_train1, clf = ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_combind_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = np.array(y_combined).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_combind_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combind_std[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

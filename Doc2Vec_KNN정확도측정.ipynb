{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Twitter\n",
    "from time import time\n",
    "import pickle\n",
    "import os\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/CE206-26/Desktop/크롤링구글맵스라벨링1.csv\",encoding='CP949')\n",
    "df2 = pd.read_csv(\"C:/Users/CE206-26/Desktop/구글맵스띄어쓰기삭제.csv\",encoding='CP949')\n",
    "df_train = df1\n",
    "df_test = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['라벨링'] = '0' ### test 데이터로 쓰기 위해서는 라벨링 필요 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1['라벨링'] = df1['라벨링'].astype('str') ### 라벨이 int면 라벨이라고 인식을 못함###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['라벨링'].dtypes ### dtype('O') 여야함###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "twitter = Twitter()\n",
    "def tokenizer_twitter_morphs(doc):\n",
    "    return twitter.morphs(doc)\n",
    "\n",
    "def tokenizer_twitter_noun(doc):\n",
    "    return twitter.nouns(doc)\n",
    "\n",
    "def tokenizer_twitter_pos(doc):\n",
    "    return twitter.pos(doc, norm=True, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = Komoran()\n",
    "def tokenizer_noun(doc):\n",
    "    return komoran.nouns(doc)\n",
    "\n",
    "def tokenizer_morphs(doc):\n",
    "    return komoran.morphs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 리뷰들 토큰화 시간 오래걸림 ###\n",
    "\n",
    "df_train['token_review'] = df_train['리뷰'].apply(tokenizer_twitter_morphs)\n",
    "df_test['X_test_tokkened'] = df_test['리뷰'].apply(tokenizer_twitter_morphs)\n",
    "tokens = [ t for d in df_train['token_review'] for t in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = nltk.Text(tokens, name='NMSC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_train_docs = [TaggedDocument(d, c) for d, c in df_train[['token_review', '라벨링']].values]\n",
    "tagged_test_docs = [TaggedDocument(d, c) for d, c in df_test[['X_test_tokkened','라벨링']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 09:38:02,796 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectorizer = Doc2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 09:38:10,223 : INFO : collecting all words and their counts\n",
      "2019-08-22 09:38:10,224 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-08-22 09:38:10,325 : INFO : collected 31035 word types and 6 unique tags from a corpus of 487 examples and 385571 words\n",
      "2019-08-22 09:38:10,326 : INFO : Loading a fresh vocabulary\n",
      "2019-08-22 09:38:10,355 : INFO : effective_min_count=5 retains 6669 unique words (21% of original 31035, drops 24366)\n",
      "2019-08-22 09:38:10,356 : INFO : effective_min_count=5 leaves 348256 word corpus (90% of original 385571, drops 37315)\n",
      "2019-08-22 09:38:10,384 : INFO : deleting the raw counts dictionary of 31035 items\n",
      "2019-08-22 09:38:10,386 : INFO : sample=0.001 downsamples 41 most-common words\n",
      "2019-08-22 09:38:10,387 : INFO : downsampling leaves estimated 278339 word corpus (79.9% of prior 348256)\n",
      "2019-08-22 09:38:10,416 : INFO : estimated required memory for 6669 words and 100 dimensions: 8673300 bytes\n",
      "2019-08-22 09:38:10,418 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/m,d100,n5,w5,mc5,s0.001,t3)\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "2019-08-22 09:38:23,826 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:24,151 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:24,162 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:24,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:24,167 : INFO : EPOCH - 1 : training on 385571 raw words (278383 effective words) took 0.3s, 828070 effective words/s\n",
      "2019-08-22 09:38:24,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:24,486 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:24,491 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:24,492 : INFO : EPOCH - 2 : training on 385571 raw words (278828 effective words) took 0.3s, 873329 effective words/s\n",
      "2019-08-22 09:38:24,799 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:24,804 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:24,811 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:24,813 : INFO : EPOCH - 3 : training on 385571 raw words (278964 effective words) took 0.3s, 882663 effective words/s\n",
      "2019-08-22 09:38:25,267 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:25,277 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:25,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:25,279 : INFO : EPOCH - 4 : training on 385571 raw words (278579 effective words) took 0.5s, 602077 effective words/s\n",
      "2019-08-22 09:38:25,580 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:25,586 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:25,589 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:25,591 : INFO : EPOCH - 5 : training on 385571 raw words (278910 effective words) took 0.3s, 905911 effective words/s\n",
      "2019-08-22 09:38:25,591 : INFO : training on a 1927855 raw words (1393664 effective words) took 1.8s, 789736 effective words/s\n",
      "2019-08-22 09:38:25,593 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-08-22 09:38:25,595 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:25,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:25,903 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:25,905 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:25,906 : INFO : EPOCH - 1 : training on 385571 raw words (279110 effective words) took 0.3s, 908632 effective words/s\n",
      "2019-08-22 09:38:26,212 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:26,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:26,218 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:26,219 : INFO : EPOCH - 2 : training on 385571 raw words (278673 effective words) took 0.3s, 901046 effective words/s\n",
      "2019-08-22 09:38:26,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:26,522 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:26,527 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:26,528 : INFO : EPOCH - 3 : training on 385571 raw words (278890 effective words) took 0.3s, 921904 effective words/s\n",
      "2019-08-22 09:38:26,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:26,831 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:26,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:26,840 : INFO : EPOCH - 4 : training on 385571 raw words (278992 effective words) took 0.3s, 907293 effective words/s\n",
      "2019-08-22 09:38:27,140 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:27,143 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:27,156 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:27,157 : INFO : EPOCH - 5 : training on 385571 raw words (278839 effective words) took 0.3s, 891117 effective words/s\n",
      "2019-08-22 09:38:27,159 : INFO : training on a 1927855 raw words (1394504 effective words) took 1.6s, 892370 effective words/s\n",
      "2019-08-22 09:38:27,160 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:27,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:27,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:27,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:27,481 : INFO : EPOCH - 1 : training on 385571 raw words (278886 effective words) took 0.3s, 879904 effective words/s\n",
      "2019-08-22 09:38:27,778 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:27,788 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:27,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:27,790 : INFO : EPOCH - 2 : training on 385571 raw words (278620 effective words) took 0.3s, 910501 effective words/s\n",
      "2019-08-22 09:38:28,084 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:28,094 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:28,095 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:28,096 : INFO : EPOCH - 3 : training on 385571 raw words (278889 effective words) took 0.3s, 922266 effective words/s\n",
      "2019-08-22 09:38:28,395 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:28,412 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:28,416 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:28,418 : INFO : EPOCH - 4 : training on 385571 raw words (278996 effective words) took 0.3s, 883760 effective words/s\n",
      "2019-08-22 09:38:28,726 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:28,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:28,739 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:28,739 : INFO : EPOCH - 5 : training on 385571 raw words (279003 effective words) took 0.3s, 874975 effective words/s\n",
      "2019-08-22 09:38:28,740 : INFO : training on a 1927855 raw words (1394394 effective words) took 1.6s, 883304 effective words/s\n",
      "2019-08-22 09:38:28,742 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:29,043 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:29,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:29,052 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:29,054 : INFO : EPOCH - 1 : training on 385571 raw words (278885 effective words) took 0.3s, 909288 effective words/s\n",
      "2019-08-22 09:38:29,352 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:29,359 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:29,364 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:29,365 : INFO : EPOCH - 2 : training on 385571 raw words (278890 effective words) took 0.3s, 905681 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 09:38:29,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:29,668 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:29,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:29,672 : INFO : EPOCH - 3 : training on 385571 raw words (279067 effective words) took 0.3s, 926505 effective words/s\n",
      "2019-08-22 09:38:29,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:29,967 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:29,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:29,981 : INFO : EPOCH - 4 : training on 385571 raw words (278866 effective words) took 0.3s, 915424 effective words/s\n",
      "2019-08-22 09:38:30,286 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:30,296 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:30,302 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:30,304 : INFO : EPOCH - 5 : training on 385571 raw words (278616 effective words) took 0.3s, 887927 effective words/s\n",
      "2019-08-22 09:38:30,304 : INFO : training on a 1927855 raw words (1394324 effective words) took 1.6s, 894079 effective words/s\n",
      "2019-08-22 09:38:30,305 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:30,601 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:30,605 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:30,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:30,611 : INFO : EPOCH - 1 : training on 385571 raw words (278804 effective words) took 0.3s, 920079 effective words/s\n",
      "2019-08-22 09:38:30,899 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:30,908 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:30,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:30,911 : INFO : EPOCH - 2 : training on 385571 raw words (278756 effective words) took 0.3s, 947079 effective words/s\n",
      "2019-08-22 09:38:31,199 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:31,206 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:31,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:31,214 : INFO : EPOCH - 3 : training on 385571 raw words (278800 effective words) took 0.3s, 935121 effective words/s\n",
      "2019-08-22 09:38:31,509 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:31,513 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:31,517 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:31,519 : INFO : EPOCH - 4 : training on 385571 raw words (278626 effective words) took 0.3s, 927095 effective words/s\n",
      "2019-08-22 09:38:31,812 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:31,816 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:31,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:31,826 : INFO : EPOCH - 5 : training on 385571 raw words (278839 effective words) took 0.3s, 920139 effective words/s\n",
      "2019-08-22 09:38:31,828 : INFO : training on a 1927855 raw words (1393825 effective words) took 1.5s, 915862 effective words/s\n",
      "2019-08-22 09:38:31,829 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:32,121 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:32,129 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:32,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:32,132 : INFO : EPOCH - 1 : training on 385571 raw words (278608 effective words) took 0.3s, 928717 effective words/s\n",
      "2019-08-22 09:38:32,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:32,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:32,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:32,445 : INFO : EPOCH - 2 : training on 385571 raw words (278914 effective words) took 0.3s, 899710 effective words/s\n",
      "2019-08-22 09:38:32,734 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:32,737 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:32,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:32,743 : INFO : EPOCH - 3 : training on 385571 raw words (279003 effective words) took 0.3s, 952727 effective words/s\n",
      "2019-08-22 09:38:33,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:33,044 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:33,052 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:33,054 : INFO : EPOCH - 4 : training on 385571 raw words (278754 effective words) took 0.3s, 908140 effective words/s\n",
      "2019-08-22 09:38:33,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:33,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:33,382 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:33,383 : INFO : EPOCH - 5 : training on 385571 raw words (278974 effective words) took 0.3s, 861680 effective words/s\n",
      "2019-08-22 09:38:33,385 : INFO : training on a 1927855 raw words (1394253 effective words) took 1.6s, 896842 effective words/s\n",
      "2019-08-22 09:38:33,386 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:33,693 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:33,703 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:33,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:33,706 : INFO : EPOCH - 1 : training on 385571 raw words (279035 effective words) took 0.3s, 879635 effective words/s\n",
      "2019-08-22 09:38:34,000 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:34,005 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:34,011 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:34,013 : INFO : EPOCH - 2 : training on 385571 raw words (278683 effective words) took 0.3s, 919344 effective words/s\n",
      "2019-08-22 09:38:34,379 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:34,397 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:34,398 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:34,399 : INFO : EPOCH - 3 : training on 385571 raw words (278791 effective words) took 0.4s, 732989 effective words/s\n",
      "2019-08-22 09:38:34,727 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:34,736 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:34,737 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:34,738 : INFO : EPOCH - 4 : training on 385571 raw words (278869 effective words) took 0.3s, 837271 effective words/s\n",
      "2019-08-22 09:38:35,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:35,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:35,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:35,122 : INFO : EPOCH - 5 : training on 385571 raw words (278847 effective words) took 0.4s, 732617 effective words/s\n",
      "2019-08-22 09:38:35,123 : INFO : training on a 1927855 raw words (1394225 effective words) took 1.7s, 802811 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 09:38:35,124 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:35,434 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:35,441 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:35,449 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:35,450 : INFO : EPOCH - 1 : training on 385571 raw words (278646 effective words) took 0.3s, 874729 effective words/s\n",
      "2019-08-22 09:38:35,740 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:35,745 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:35,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:35,750 : INFO : EPOCH - 2 : training on 385571 raw words (278966 effective words) took 0.3s, 942100 effective words/s\n",
      "2019-08-22 09:38:36,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:36,117 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:36,119 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:36,121 : INFO : EPOCH - 3 : training on 385571 raw words (278411 effective words) took 0.4s, 765146 effective words/s\n",
      "2019-08-22 09:38:36,515 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:36,520 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:36,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:36,527 : INFO : EPOCH - 4 : training on 385571 raw words (278733 effective words) took 0.4s, 693721 effective words/s\n",
      "2019-08-22 09:38:36,826 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:36,835 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:36,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:36,842 : INFO : EPOCH - 5 : training on 385571 raw words (278746 effective words) took 0.3s, 892656 effective words/s\n",
      "2019-08-22 09:38:36,844 : INFO : training on a 1927855 raw words (1393502 effective words) took 1.7s, 810703 effective words/s\n",
      "2019-08-22 09:38:36,846 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:37,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:37,136 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:37,141 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:37,143 : INFO : EPOCH - 1 : training on 385571 raw words (279029 effective words) took 0.3s, 952796 effective words/s\n",
      "2019-08-22 09:38:37,434 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:37,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:37,447 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:37,448 : INFO : EPOCH - 2 : training on 385571 raw words (278880 effective words) took 0.3s, 923915 effective words/s\n",
      "2019-08-22 09:38:37,763 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:37,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:37,779 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:37,783 : INFO : EPOCH - 3 : training on 385571 raw words (278574 effective words) took 0.3s, 847449 effective words/s\n",
      "2019-08-22 09:38:38,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:38,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:38,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:38,123 : INFO : EPOCH - 4 : training on 385571 raw words (278644 effective words) took 0.3s, 847406 effective words/s\n",
      "2019-08-22 09:38:38,507 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:38,514 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:38,516 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:38,518 : INFO : EPOCH - 5 : training on 385571 raw words (278767 effective words) took 0.4s, 713788 effective words/s\n",
      "2019-08-22 09:38:38,520 : INFO : training on a 1927855 raw words (1393894 effective words) took 1.7s, 833416 effective words/s\n",
      "2019-08-22 09:38:38,521 : INFO : training model with 3 workers on 6669 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 09:38:38,868 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:38,881 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:38,883 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:38,885 : INFO : EPOCH - 1 : training on 385571 raw words (279159 effective words) took 0.4s, 783886 effective words/s\n",
      "2019-08-22 09:38:39,299 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:39,307 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:39,310 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:39,311 : INFO : EPOCH - 2 : training on 385571 raw words (278845 effective words) took 0.4s, 664430 effective words/s\n",
      "2019-08-22 09:38:39,668 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:39,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:39,683 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:39,684 : INFO : EPOCH - 3 : training on 385571 raw words (278770 effective words) took 0.4s, 765515 effective words/s\n",
      "2019-08-22 09:38:40,077 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:40,085 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:40,087 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:40,087 : INFO : EPOCH - 4 : training on 385571 raw words (278917 effective words) took 0.4s, 697915 effective words/s\n",
      "2019-08-22 09:38:40,430 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 09:38:40,441 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 09:38:40,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 09:38:40,444 : INFO : EPOCH - 5 : training on 385571 raw words (279031 effective words) took 0.4s, 789937 effective words/s\n",
      "2019-08-22 09:38:40,446 : INFO : training on a 1927855 raw words (1394722 effective words) took 1.9s, 725442 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During Time: 16.621432304382324\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "end = time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 09:40:35,927 : INFO : saving Doc2Vec object under Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model, separately None\n",
      "2019-08-22 09:40:36,013 : INFO : saved Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model'\n",
    "doc_vectorizer.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 11:00:14,392 : INFO : loading Doc2Vec object from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model\n",
      "2019-08-22 11:00:14,462 : INFO : loading vocabulary recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.vocabulary.* with mmap=None\n",
      "2019-08-22 11:00:14,464 : INFO : loading trainables recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.trainables.* with mmap=None\n",
      "2019-08-22 11:00:14,466 : INFO : loading wv recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.wv.* with mmap=None\n",
      "2019-08-22 11:00:14,467 : INFO : loading docvecs recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.docvecs.* with mmap=None\n",
      "2019-08-22 11:00:14,469 : INFO : loaded Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer = Doc2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "y_train = [doc.tags for doc in tagged_train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [doc.tags for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487 487\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.asarray(y_train)\n",
    "y_test_np = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.eye(7)[y_train_np.astype('int').reshape(-1)]\n",
    "y_test_np = np.eye(7)[y_test_np.astype('int').reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=6, algorithm='ball_tree').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.48203564, -0.6243266 ,  0.15739882, -0.76039356, -0.57809967,\n",
       "       -1.0096    ,  0.59068424,  1.2903953 , -0.1569971 , -0.49474514,\n",
       "        0.59646636, -1.1688079 ,  0.7644317 ,  0.46162194,  0.56518203,\n",
       "        0.10650347,  0.2075075 ,  1.1108743 ,  0.5377022 ,  0.9643238 ,\n",
       "       -0.3602644 , -0.5512547 ,  0.18889445,  0.5664211 ,  0.27161875,\n",
       "       -0.9321773 , -0.551525  ,  0.22762342, -0.30506584, -0.93813175,\n",
       "       -0.62588614,  1.3426479 , -0.08452383,  0.3199109 , -0.15890029,\n",
       "        0.90663594,  0.13211389, -0.5592338 , -0.39105272, -0.44546893,\n",
       "        0.5469872 ,  0.8939225 ,  1.6384526 ,  0.18271182, -0.04576356,\n",
       "        0.39523944,  1.1815152 , -0.46333578, -1.1842191 , -0.5022238 ,\n",
       "        0.6218391 ,  0.659987  ,  0.3665604 ,  0.7438687 ,  0.12923557,\n",
       "        0.06497975, -0.61321247,  0.58036715, -0.1283809 , -0.3766289 ,\n",
       "       -0.61781293, -0.31019232,  0.3512921 ,  0.08782116, -0.62938935,\n",
       "        0.5141684 ,  0.4477248 ,  0.97339994, -0.12809664,  0.55802405,\n",
       "       -1.2035764 ,  0.7488416 , -0.3987892 , -0.03815582, -0.49397606,\n",
       "        1.2826374 ,  1.8201771 , -0.18935226,  0.3477394 ,  1.2089093 ,\n",
       "       -0.36322683,  0.3294552 ,  0.8262903 ,  0.3843696 ,  0.0838892 ,\n",
       "       -0.7185259 , -0.26016402,  1.2168746 , -0.44537115,  0.03937633,\n",
       "        0.30269742,  0.5545517 ,  0.6848872 , -0.46090952, -0.5420948 ,\n",
       "        0.5186791 , -0.0065933 ,  0.06881038,  0.42830476,  0.04038716],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = KNeighborsClassifier(n_neighbors = 6, p=2, metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "ml.fit(X_train_np,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = ml.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 테스트 개수:974, 오류개수:974\n",
      "정확도: 0.000\n"
     ]
    }
   ],
   "source": [
    "print('총 테스트 개수:%d, 오류개수:%d' %(len(y_test), (y_test != y_pred).sum()))\n",
    "print('정확도: %.3f' %accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 테스트 개수:974, 오류개수:974\n",
      "정확도: 0.000\n"
     ]
    }
   ],
   "source": [
    "print('총 테스트 개수:%d, 오류개수:%d' %(len(y_test), (y_test != y_pred).sum()))\n",
    "print('정확도: %.3f' %accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6' '4' '2' '1' '4' '1' '1' '1' '1' '6' '4' '6' '1' '6' '6' '1' '1' '1'\n",
      " '4' '6' '2' '1' '2' '6' '4' '4' '1' '6' '6' '4' '1' '4' '4' '2' '4' '1'\n",
      " '4' '1' '1' '1' '4' '4' '6' '1' '1' '4' '1' '4' '4' '4' '2' '2' '4' '4'\n",
      " '6' '1' '4' '1' '6' '6' '4' '1' '1' '3' '6' '6' '4' '1' '3' '6' '6' '1'\n",
      " '1' '6' '1' '3' '1' '1' '4' '1' '1' '1' '1' '6' '1' '1' '4' '1' '1' '4'\n",
      " '1' '1' '3' '1' '6' '1' '2' '6' '1' '4' '1' '6' '1' '1' '2' '4' '1' '6'\n",
      " '2' '1' '4' '4' '1' '4' '1' '6' '4' '6' '2' '4' '1' '6' '4' '4' '1' '6'\n",
      " '2' '1' '1' '4' '4' '1' '6' '6' '4' '1' '6' '4' '1' '4' '6' '3' '1' '6'\n",
      " '1' '1' '4' '1' '1' '1' '1' '4' '1' '6' '1' '1' '6' '1' '4' '6' '2' '4'\n",
      " '4' '4' '1' '6' '6' '1' '4' '1' '4' '1' '4' '1' '1' '1' '1' '6' '4' '1'\n",
      " '4' '1' '1' '2' '4' '6' '6' '1' '5' '4' '6' '4' '1' '4' '6' '2' '3' '1'\n",
      " '1' '6' '2' '6' '3' '4' '6' '3' '6' '6' '1' '4' '6' '1' '4' '6' '6' '6'\n",
      " '1' '4' '1' '1' '1' '2' '2' '6' '1' '4' '3' '1' '4' '2' '6' '1' '1' '1'\n",
      " '2' '6' '1' '4' '1' '1' '4' '1' '2' '4' '6' '1' '6' '6' '1' '1' '1' '4'\n",
      " '6' '1' '1' '6' '4' '6' '2' '6' '6' '6' '6' '4' '4' '1' '6' '4' '1' '1'\n",
      " '6' '2' '1' '6' '6' '1' '2' '1' '6' '6' '1' '1' '1' '1' '2' '1' '6' '6'\n",
      " '6' '4' '1' '1' '3' '1' '1' '6' '4' '1' '1' '2' '1' '4' '1' '2' '6' '6'\n",
      " '6' '2' '1' '6' '1' '4' '3' '1' '6' '6' '1' '1' '6' '1' '1' '1' '2' '2'\n",
      " '1' '1' '6' '4' '2' '4' '4' '2' '4' '3' '1' '4' '4' '1' '1' '1' '1' '1'\n",
      " '1' '6' '2' '6' '1' '1' '2' '1' '1' '5' '6' '2' '6' '1' '1' '5' '1' '6'\n",
      " '5' '1' '2' '1' '1' '2' '1' '1' '1' '1' '1' '1' '1' '6' '1' '2' '6' '1'\n",
      " '1' '1' '1' '1' '6' '1' '1' '2' '1' '6' '6' '6' '1' '2' '1' '6' '6' '1'\n",
      " '1' '1' '1' '1' '6' '1' '1' '1' '1' '1' '1' '2' '1' '1' '1' '6' '1' '1'\n",
      " '1' '6' '1' '1' '1' '1' '1' '2' '1' '6' '1' '1' '2' '1' '2' '1' '1' '1'\n",
      " '2' '6' '3' '2' '1' '1' '6' '1' '3' '1' '1' '1' '4' '1' '6' '6' '1' '4'\n",
      " '6' '1' '1' '1' '2' '2' '6' '6' '6' '4' '1' '2' '4' '2' '4' '6' '6' '2'\n",
      " '1' '6' '6' '1' '1' '6' '1' '6' '2' '1' '1' '1' '1' '1' '4' '1' '2' '4'\n",
      " '1' '3' '1' '1' '1' '5' '1' '6' '1' '1' '1' '1' '1' '1' '3' '5' '1' '6'\n",
      " '1' '1' '1' '6' '1' '3' '6' '1' '4' '1' '1' '2' '6' '1' '1' '1' '1' '1'\n",
      " '6' '1' '1' '1' '1' '1' '1' '2' '1' '2' '1' '1' '1' '1' '1' '1' '1' '6'\n",
      " '1' '1' '2' '1' '1' '1' '1' '2' '2' '1' '1' '2' '1' '6' '1' '2' '6' '1'\n",
      " '1' '1' '1' '6' '1' '6' '1' '1' '6' '1' '2' '1' '1' '1' '6' '6' '1' '1'\n",
      " '6' '1' '1' '1' '1' '1' '6' '1' '1' '1' '1' '1' '3' '1' '1' '1' '6' '6'\n",
      " '1' '1' '6' '6' '1' '2' '6' '1' '1' '1' '6' '3' '1' '3' '1' '1' '1' '1'\n",
      " '1' '1' '1' '5' '1' '1' '1' '2' '2' '1' '1' '6' '1' '1' '1' '6' '1' '1'\n",
      " '2' '6' '2' '1' '1' '1' '6' '1' '1' '1' '6' '1' '1' '6' '1' '1' '6' '6'\n",
      " '6' '1' '1' '1' '1' '6' '1' '1' '2' '1' '1' '1' '1' '1' '2' '5' '5' '2'\n",
      " '1' '1' '4' '1' '4' '1' '1' '4' '4' '6' '4' '1' '1' '2' '4' '2' '6' '4'\n",
      " '6' '1' '6' '4' '2' '4' '6' '4' '4' '1' '1' '2' '1' '1' '1' '4' '1' '2'\n",
      " '1' '4' '4' '4' '4' '6' '1' '6' '1' '3' '6' '4' '1' '6' '4' '6' '1' '1'\n",
      " '4' '4' '6' '6' '6' '1' '6' '1' '4' '2' '6' '6' '6' '1' '1' '1' '6' '1'\n",
      " '4' '4' '1' '4' '1' '1' '6' '1' '4' '6' '6' '2' '6' '1' '1' '6' '4' '4'\n",
      " '1' '1' '6' '3' '6' '6' '5' '4' '6' '4' '4' '1' '1' '4' '1' '6' '1' '1'\n",
      " '6' '1' '1' '6' '4' '2' '6' '1' '1' '1' '1' '1' '1' '1' '1' '4' '1' '1'\n",
      " '6' '1' '1' '4' '1' '4' '4' '1' '4' '6' '1' '6' '4' '6' '1' '4' '4' '1'\n",
      " '6' '2' '6' '6' '1' '1' '1' '3' '6' '1' '2' '1' '4' '4' '4' '4' '6' '4'\n",
      " '1' '1' '1' '1' '1' '4' '1' '4' '4' '4' '6' '6' '6' '4' '1' '6' '1' '1'\n",
      " '4' '4' '6' '4' '1' '6' '1' '4' '1' '4' '1' '1' '4' '4' '4' '1' '4' '4'\n",
      " '4' '4' '1' '1' '2' '1' '2' '6' '1' '4' '1' '4' '1' '6' '6' '4' '4' '1'\n",
      " '4' '4' '6' '1' '6' '6' '4' '6' '1' '1' '6' '4' '6' '1' '2' '4' '4' '1'\n",
      " '1' '4' '6' '4' '2' '1' '1' '1' '4' '6' '1' '2' '1' '6' '4' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '6' '4' '1' '1' '2' '1' '2' '4' '4' '1'\n",
      " '4' '4' '6' '1' '1' '1' '2' '1' '1' '2' '1' '1' '1' '1' '1' '1' '1' '6'\n",
      " '6' '6' '1' '1' '1' '1' '5' '6' '6' '1' '1' '1' '1' '4' '1' '1' '1' '2'\n",
      " '1' '1']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

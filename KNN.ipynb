{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Twitter\n",
    "from time import time\n",
    "import pickle\n",
    "import os\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/CE206-26/Desktop/크롤링구글맵스라벨링1.csv\",encoding='CP949')\n",
    "df2 = pd.read_csv(\"C:/Users/CE206-26/Desktop/구글맵스띄어쓰기삭제.csv\",encoding='CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1['라벨링'] = df1['라벨링'].astype('str') ### 라벨이 int면 라벨이라고 인식을 못함###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###이거나###\n",
    "\n",
    "df_train = df1\n",
    "df_test = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "###이거###\n",
    "\n",
    "df_train = df1[330:]\n",
    "df_test = df1[331:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['라벨링'] = '0' ### test 데이터로 쓰기 위해서는 라벨링 필요 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['라벨링'].dtypes ### dtype('O') 여야함###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "twitter = Twitter()\n",
    "def tokenizer_twitter_morphs(doc):\n",
    "    return twitter.morphs(doc)\n",
    "\n",
    "def tokenizer_twitter_noun(doc):\n",
    "    return twitter.nouns(doc)\n",
    "\n",
    "def tokenizer_twitter_pos(doc):\n",
    "    return twitter.pos(doc, norm=True, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = Komoran()\n",
    "def tokenizer_noun(doc):\n",
    "    return komoran.nouns(doc)\n",
    "\n",
    "def tokenizer_morphs(doc):\n",
    "    return komoran.morphs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "### 리뷰들 토큰화 시간 오래걸림 ###\n",
    "\n",
    "df_train['token_review'] = df_train['리뷰'].apply(tokenizer_twitter_morphs)\n",
    "df_test['X_test_tokkened'] = df_test['리뷰'].apply(tokenizer_twitter_morphs)\n",
    "tokens = [ t for d in df_train['token_review'] for t in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = nltk.Text(tokens, name='NMSC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_train_docs = [TaggedDocument(d, c) for d, c in df_train[['token_review', '라벨링']].values]\n",
    "tagged_test_docs = [TaggedDocument(d, c) for d, c in df_test[['X_test_tokkened','라벨링']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectorizer = Doc2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 15:28:48,400 : INFO : collecting all words and their counts\n",
      "2019-08-22 15:28:48,401 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-08-22 15:28:48,451 : INFO : collected 16418 word types and 6 unique tags from a corpus of 157 examples and 136053 words\n",
      "2019-08-22 15:28:48,451 : INFO : Loading a fresh vocabulary\n",
      "2019-08-22 15:28:48,473 : INFO : effective_min_count=5 retains 3168 unique words (19% of original 16418, drops 13250)\n",
      "2019-08-22 15:28:48,474 : INFO : effective_min_count=5 leaves 115978 word corpus (85% of original 136053, drops 20075)\n",
      "2019-08-22 15:28:48,488 : INFO : deleting the raw counts dictionary of 16418 items\n",
      "2019-08-22 15:28:48,489 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2019-08-22 15:28:48,490 : INFO : downsampling leaves estimated 89686 word corpus (77.3% of prior 115978)\n",
      "2019-08-22 15:28:48,508 : INFO : estimated required memory for 3168 words and 100 dimensions: 4122000 bytes\n",
      "2019-08-22 15:28:48,510 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/m,d100,n5,w5,mc5,s0.001,t3)\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CE206-26\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "2019-08-22 15:28:50,809 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:50,920 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:50,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:50,924 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:50,925 : INFO : EPOCH - 1 : training on 136053 raw words (89831 effective words) took 0.1s, 802392 effective words/s\n",
      "2019-08-22 15:28:51,034 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:51,036 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:51,037 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:51,039 : INFO : EPOCH - 2 : training on 136053 raw words (89865 effective words) took 0.1s, 811877 effective words/s\n",
      "2019-08-22 15:28:51,139 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:51,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:51,148 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:51,149 : INFO : EPOCH - 3 : training on 136053 raw words (89928 effective words) took 0.1s, 844049 effective words/s\n",
      "2019-08-22 15:28:51,247 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:51,250 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:51,258 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:51,259 : INFO : EPOCH - 4 : training on 136053 raw words (90006 effective words) took 0.1s, 842592 effective words/s\n",
      "2019-08-22 15:28:51,363 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:51,373 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:51,376 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:51,377 : INFO : EPOCH - 5 : training on 136053 raw words (89875 effective words) took 0.1s, 799551 effective words/s\n",
      "2019-08-22 15:28:51,378 : INFO : training on a 680265 raw words (449505 effective words) took 0.6s, 791255 effective words/s\n",
      "2019-08-22 15:28:51,379 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-08-22 15:28:51,380 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:51,516 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:51,521 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:51,523 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:51,524 : INFO : EPOCH - 1 : training on 136053 raw words (89755 effective words) took 0.1s, 647356 effective words/s\n",
      "2019-08-22 15:28:51,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:51,651 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:51,655 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:51,656 : INFO : EPOCH - 2 : training on 136053 raw words (89748 effective words) took 0.1s, 715157 effective words/s\n",
      "2019-08-22 15:28:51,752 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:51,761 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:51,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:51,763 : INFO : EPOCH - 3 : training on 136053 raw words (89861 effective words) took 0.1s, 857068 effective words/s\n",
      "2019-08-22 15:28:51,869 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:51,872 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:51,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:51,878 : INFO : EPOCH - 4 : training on 136053 raw words (89789 effective words) took 0.1s, 806464 effective words/s\n",
      "2019-08-22 15:28:52,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:52,022 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:52,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:52,030 : INFO : EPOCH - 5 : training on 136053 raw words (89811 effective words) took 0.1s, 602360 effective words/s\n",
      "2019-08-22 15:28:52,031 : INFO : training on a 680265 raw words (448964 effective words) took 0.6s, 692248 effective words/s\n",
      "2019-08-22 15:28:52,032 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:52,156 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:52,158 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:52,163 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:52,164 : INFO : EPOCH - 1 : training on 136053 raw words (89768 effective words) took 0.1s, 704673 effective words/s\n",
      "2019-08-22 15:28:52,274 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:52,285 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:52,287 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:52,288 : INFO : EPOCH - 2 : training on 136053 raw words (89908 effective words) took 0.1s, 743513 effective words/s\n",
      "2019-08-22 15:28:52,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:52,434 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:52,436 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:52,437 : INFO : EPOCH - 3 : training on 136053 raw words (89748 effective words) took 0.1s, 616260 effective words/s\n",
      "2019-08-22 15:28:52,548 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:52,553 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:52,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:52,556 : INFO : EPOCH - 4 : training on 136053 raw words (89733 effective words) took 0.1s, 784184 effective words/s\n",
      "2019-08-22 15:28:52,682 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:52,689 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:52,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:52,692 : INFO : EPOCH - 5 : training on 136053 raw words (89898 effective words) took 0.1s, 679029 effective words/s\n",
      "2019-08-22 15:28:52,692 : INFO : training on a 680265 raw words (449055 effective words) took 0.7s, 680733 effective words/s\n",
      "2019-08-22 15:28:52,693 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:52,814 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:52,816 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:52,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:52,818 : INFO : EPOCH - 1 : training on 136053 raw words (89991 effective words) took 0.1s, 746589 effective words/s\n",
      "2019-08-22 15:28:52,916 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:52,921 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:52,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:52,924 : INFO : EPOCH - 2 : training on 136053 raw words (89987 effective words) took 0.1s, 879567 effective words/s\n",
      "2019-08-22 15:28:53,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:53,030 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:53,033 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:53,034 : INFO : EPOCH - 3 : training on 136053 raw words (89964 effective words) took 0.1s, 843914 effective words/s\n",
      "2019-08-22 15:28:53,145 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:53,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:53,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:53,156 : INFO : EPOCH - 4 : training on 136053 raw words (89893 effective words) took 0.1s, 751915 effective words/s\n",
      "2019-08-22 15:28:53,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:53,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:53,297 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:53,299 : INFO : EPOCH - 5 : training on 136053 raw words (89894 effective words) took 0.1s, 657439 effective words/s\n",
      "2019-08-22 15:28:53,300 : INFO : training on a 680265 raw words (449729 effective words) took 0.6s, 742775 effective words/s\n",
      "2019-08-22 15:28:53,301 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:53,410 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:53,418 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:53,424 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:53,426 : INFO : EPOCH - 1 : training on 136053 raw words (89679 effective words) took 0.1s, 766081 effective words/s\n",
      "2019-08-22 15:28:53,533 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:53,535 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:53,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:53,538 : INFO : EPOCH - 2 : training on 136053 raw words (89919 effective words) took 0.1s, 823361 effective words/s\n",
      "2019-08-22 15:28:53,658 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:53,661 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:53,667 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:53,668 : INFO : EPOCH - 3 : training on 136053 raw words (89790 effective words) took 0.1s, 717502 effective words/s\n",
      "2019-08-22 15:28:53,763 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:53,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:53,769 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:53,770 : INFO : EPOCH - 4 : training on 136053 raw words (89778 effective words) took 0.1s, 906342 effective words/s\n",
      "2019-08-22 15:28:53,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:53,871 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:53,874 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:53,875 : INFO : EPOCH - 5 : training on 136053 raw words (89955 effective words) took 0.1s, 883973 effective words/s\n",
      "2019-08-22 15:28:53,876 : INFO : training on a 680265 raw words (449121 effective words) took 0.6s, 784592 effective words/s\n",
      "2019-08-22 15:28:53,877 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:53,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:53,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:53,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:53,991 : INFO : EPOCH - 1 : training on 136053 raw words (89902 effective words) took 0.1s, 818605 effective words/s\n",
      "2019-08-22 15:28:54,089 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:54,095 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:54,100 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:54,101 : INFO : EPOCH - 2 : training on 136053 raw words (89913 effective words) took 0.1s, 843734 effective words/s\n",
      "2019-08-22 15:28:54,202 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:54,212 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:54,213 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:54,214 : INFO : EPOCH - 3 : training on 136053 raw words (89965 effective words) took 0.1s, 818454 effective words/s\n",
      "2019-08-22 15:28:54,323 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:54,328 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:54,331 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:54,332 : INFO : EPOCH - 4 : training on 136053 raw words (89900 effective words) took 0.1s, 803689 effective words/s\n",
      "2019-08-22 15:28:54,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:54,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:54,436 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:54,437 : INFO : EPOCH - 5 : training on 136053 raw words (89741 effective words) took 0.1s, 879751 effective words/s\n",
      "2019-08-22 15:28:54,438 : INFO : training on a 680265 raw words (449421 effective words) took 0.6s, 801308 effective words/s\n",
      "2019-08-22 15:28:54,440 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:54,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:54,553 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:54,556 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:54,558 : INFO : EPOCH - 1 : training on 136053 raw words (89850 effective words) took 0.1s, 802967 effective words/s\n",
      "2019-08-22 15:28:54,676 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:54,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:54,685 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:54,686 : INFO : EPOCH - 2 : training on 136053 raw words (89941 effective words) took 0.1s, 722441 effective words/s\n",
      "2019-08-22 15:28:54,801 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:54,809 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:54,812 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:54,814 : INFO : EPOCH - 3 : training on 136053 raw words (89918 effective words) took 0.1s, 719057 effective words/s\n",
      "2019-08-22 15:28:54,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:54,940 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:54,941 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:54,942 : INFO : EPOCH - 4 : training on 136053 raw words (89870 effective words) took 0.1s, 730320 effective words/s\n",
      "2019-08-22 15:28:55,082 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:55,088 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:55,089 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:55,090 : INFO : EPOCH - 5 : training on 136053 raw words (89881 effective words) took 0.1s, 628707 effective words/s\n",
      "2019-08-22 15:28:55,091 : INFO : training on a 680265 raw words (449460 effective words) took 0.6s, 691553 effective words/s\n",
      "2019-08-22 15:28:55,092 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:55,201 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:55,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:55,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:55,208 : INFO : EPOCH - 1 : training on 136053 raw words (89925 effective words) took 0.1s, 800488 effective words/s\n",
      "2019-08-22 15:28:55,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:55,304 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:55,310 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:55,311 : INFO : EPOCH - 2 : training on 136053 raw words (89755 effective words) took 0.1s, 906154 effective words/s\n",
      "2019-08-22 15:28:55,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:55,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:55,423 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:55,424 : INFO : EPOCH - 3 : training on 136053 raw words (89927 effective words) took 0.1s, 845122 effective words/s\n",
      "2019-08-22 15:28:55,531 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:55,534 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:55,539 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:55,540 : INFO : EPOCH - 4 : training on 136053 raw words (89824 effective words) took 0.1s, 800971 effective words/s\n",
      "2019-08-22 15:28:55,643 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:55,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:55,654 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:55,655 : INFO : EPOCH - 5 : training on 136053 raw words (89985 effective words) took 0.1s, 854205 effective words/s\n",
      "2019-08-22 15:28:55,658 : INFO : training on a 680265 raw words (449416 effective words) took 0.6s, 797050 effective words/s\n",
      "2019-08-22 15:28:55,659 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:55,753 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:55,756 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:55,761 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:55,762 : INFO : EPOCH - 1 : training on 136053 raw words (89881 effective words) took 0.1s, 892558 effective words/s\n",
      "2019-08-22 15:28:55,885 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:55,887 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:55,892 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:55,893 : INFO : EPOCH - 2 : training on 136053 raw words (89759 effective words) took 0.1s, 721072 effective words/s\n",
      "2019-08-22 15:28:56,023 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:56,028 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:56,033 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:56,034 : INFO : EPOCH - 3 : training on 136053 raw words (89974 effective words) took 0.1s, 660865 effective words/s\n",
      "2019-08-22 15:28:56,138 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:56,139 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:56,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:56,143 : INFO : EPOCH - 4 : training on 136053 raw words (89918 effective words) took 0.1s, 849675 effective words/s\n",
      "2019-08-22 15:28:56,247 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:56,253 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:56,256 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:56,257 : INFO : EPOCH - 5 : training on 136053 raw words (90079 effective words) took 0.1s, 814390 effective words/s\n",
      "2019-08-22 15:28:56,258 : INFO : training on a 680265 raw words (449611 effective words) took 0.6s, 750709 effective words/s\n",
      "2019-08-22 15:28:56,258 : INFO : training model with 3 workers on 3168 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-08-22 15:28:56,360 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:56,363 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:56,365 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:56,366 : INFO : EPOCH - 1 : training on 136053 raw words (89776 effective words) took 0.1s, 863727 effective words/s\n",
      "2019-08-22 15:28:56,465 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:56,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:56,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:56,470 : INFO : EPOCH - 2 : training on 136053 raw words (89957 effective words) took 0.1s, 902309 effective words/s\n",
      "2019-08-22 15:28:56,571 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:56,582 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:56,588 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:56,589 : INFO : EPOCH - 3 : training on 136053 raw words (89982 effective words) took 0.1s, 774234 effective words/s\n",
      "2019-08-22 15:28:56,711 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:56,712 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:56,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:56,715 : INFO : EPOCH - 4 : training on 136053 raw words (89986 effective words) took 0.1s, 751594 effective words/s\n",
      "2019-08-22 15:28:56,820 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-22 15:28:56,825 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-22 15:28:56,830 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-22 15:28:56,832 : INFO : EPOCH - 5 : training on 136053 raw words (89737 effective words) took 0.1s, 791142 effective words/s\n",
      "2019-08-22 15:28:56,833 : INFO : training on a 680265 raw words (449438 effective words) took 0.6s, 784015 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During Time: 6.024529218673706\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "end = time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 15:28:59,159 : INFO : saving Doc2Vec object under Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model, separately None\n",
      "2019-08-22 15:28:59,203 : INFO : saved Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model'\n",
    "doc_vectorizer.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 15:28:59,845 : INFO : loading Doc2Vec object from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model\n",
      "2019-08-22 15:28:59,873 : INFO : loading vocabulary recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.vocabulary.* with mmap=None\n",
      "2019-08-22 15:28:59,875 : INFO : loading trainables recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.trainables.* with mmap=None\n",
      "2019-08-22 15:28:59,875 : INFO : loading wv recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.wv.* with mmap=None\n",
      "2019-08-22 15:28:59,876 : INFO : loading docvecs recursively from Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model.docvecs.* with mmap=None\n",
      "2019-08-22 15:28:59,877 : INFO : loaded Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer = Doc2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "y_train = [doc.tags for doc in tagged_train_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [doc.tags for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 330\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_np), len(y_train_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.asarray(y_train)\n",
    "y_test_np = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.eye(7)[y_train_np.astype('int').reshape(-1)]\n",
    "y_test_np = np.eye(7)[y_test_np.astype('int').reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = KNeighborsClassifier(n_neighbors = 6, p=2, metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.fit(X_train_np,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4', '1', '1', '2', '1', '2', '1', '1', '2', '1', '1', '1', '5',\n",
       "       '1', '1', '1', '6', '1', '1', '1', '2', '1', '1', '1', '1', '1',\n",
       "       '6', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '6', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '2', '1', '6', '1', '1', '1', '6', '1', '1',\n",
       "       '6', '6', '6', '6', '6', '6', '6', '6', '6', '6', '1', '4', '4',\n",
       "       '2', '6', '6', '6', '6', '6', '2', '6', '1', '3', '3', '6', '3',\n",
       "       '6', '3', '1', '6', '4', '1', '6', '6', '1', '1', '1', '1', '2',\n",
       "       '1', '1', '6', '1', '1', '2', '1', '1', '4', '3', '1', '6', '1',\n",
       "       '1', '1', '6', '4', '1', '3', '3', '1', '3', '3', '3', '1', '1',\n",
       "       '1', '1', '6', '1', '6', '6', '1', '1', '1', '1', '1', '6', '1'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 테스트 개수:156, 오류개수:37\n",
      "정확도: 0.763\n"
     ]
    }
   ],
   "source": [
    "print('총 테스트 개수:%d, 오류개수:%d' %(len(y_test), (y_test != y_pred).sum()))\n",
    "print('정확도: %.3f' %accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
